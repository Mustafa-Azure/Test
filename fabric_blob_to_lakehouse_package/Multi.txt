from pyspark.sql import functions as F

def compute_sha256(path: str) -> str:
    """Compute SHA256 checksum of a file"""
    with mssparkutils.fs.open(path, "rb") as f:
        sha = hashlib.sha256()
        while chunk := f.read(8192):
            sha.update(chunk)
    return sha.hexdigest()

df = spark.createDataFrame(validation_records)

# Append to existing table
df.write.mode("append").saveAsTable("FileCopyValidation")

# Load tables
orchestration_df = spark.read.table("Lakehouse.orchestration")
config_df = spark.read.table("Lakehouse.configuration")

# Pivot config table
pivoted_config = (
    config_df
    .groupBy("process_id")
    .pivot("config_name")
    .agg(F.first("config_value"))
)

# Join with orchestration
final_df = orchestration_df.join(pivoted_config, on="process_id", how="inner")

# Convert to dictionary
final_dict = (
    final_df.rdd
    .map(lambda row: (
        row["process_id"],
        {
            "process_name": row["process_name"],
            "account_name": row["account_name"],
            "container_name": row["container_name"]
        }
    ))
    .collectAsMap()
)

# Example usage
for pid, details in final_dict.items():
    print(pid, details)
